# Hudl Web Parser Project

## Overview

This project is a web parser specifically designed for Hudl. It leverages Selenium for web automation, Pillow for image processing, and Pandas for data manipulation. The script automates interactions with web pages on Hudl, extracts necessary information, and processes the data for analysis or storage.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes.

### Prerequisites

Before you begin, ensure you have the following installed:
- Python 3.11
- pip (Python package installer)

### Installation

Follow these steps to set up the project environment:

1. **Clone the repository**

   Start by cloning the project repository to your local machine:

git clone <repository-url>


2. **Navigate to the project directory**

Change into the project directory:

cd <project-directory>


3. **Create a virtual environment**

Create a virtual environment named `venv` within the project directory:

python -m venv venv


4. **Activate the virtual environment**

Activate the virtual environment using the following command:

- On Windows:

  ```
  venv\Scripts\activate
  ```

- On macOS and Linux:

  ```
  source venv/bin/activate
  ```

5. **Install dependencies**

Install the project's dependencies from the `requirements.txt` file:

pip install -r requirements.txt


### Usage

Here's how to run the web parser script:

(Here, you would insert specific instructions on how to run your web parser, including any command-line arguments, configuration files, or environment variables needed.)

For example:

python scrap.py

